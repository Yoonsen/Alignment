{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9f712e",
   "metadata": {},
   "source": [
    "# Compare translations\n",
    "\n",
    "Two works are compared using frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b62dee-5495-4f82-92a9-c36a54ce40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dhlab as dh\n",
    "\n",
    "import dhlab.module_update as mu\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "import dhlab.nbtext as nb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c911e29c-8608-4d9b-a0f7-b531af3508a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>@import url(http://fonts.googleapis.com/css?family=Lato|Philosopher|Montserrat|Source+Code+Pro|Merriweather|Shippori+Mincho|Istok+Web|Philosopher|Assistant:200,400,700);\n",
       "\n",
       "p {\n",
       "    font-size:1.3em;\n",
       "    font-family:serif;\n",
       "    line-height:1.4em;\n",
       "    color:#142850;\n",
       "}\n",
       "h1, h2, h3, h4 {\n",
       "    color:#27496d;\n",
       "}\n",
       "\n",
       "/*\n",
       ".prompt, .jp-InputPrompt, .jp-InputArea-prompt, .jp-OutputPrompt, .jp-OutputArea-prompt {\n",
       "    visibility: hidden; \n",
       "}\n",
       "\n",
       "\n",
       ".jp-CodeCell .jp-Notebook-cell    {\n",
       "    margin-left:10%;\n",
       "    margin-right:5%;\n",
       "}\n",
       "\n",
       "\n",
       ".jp-InputArea, .jp-OutputArea {\n",
       "    margin-left:2.5em;\n",
       "    margin-right:2.5em;\n",
       "}\n",
       "*/\n",
       "\n",
       "\n",
       "body  {\n",
       "    margin:10%;\n",
       "    counter-reset: h1counter;\n",
       "\n",
       "}\n",
       "\n",
       "/* .jp-MarkdownOutput, .text_cell_render {\n",
       "\n",
       "    background-color:#FEFBF1;    \n",
       "    border-style: solid;\n",
       "    border-width: 1px;\n",
       "    border-color: rgba(0,0,0, 0.10);;\n",
       "} */\n",
       "\n",
       "\n",
       "h1:after {\n",
       "    content: \"\"; /* This is necessary for the pseudo element to work. */ \n",
       "    display: block; /* This will put the pseudo element on its own line. */\n",
       "    /*margin: 0 auto; This will center the border. */\n",
       "    width: 50%; /* Change this to whatever width you want. */\n",
       "    padding-top: 10px;\n",
       "    border-bottom:3px solid SlateGray; /* FireBrick; */\n",
       "}\n",
       "\n",
       "h2:after {\n",
       "    content: \"\"; /* This is necessary for the pseudo element to work. */ \n",
       "    display: block; /* This will put the pseudo element on its own line. */\n",
       "    /*margin: 0 auto; This will center the border. */\n",
       "    width: 30%; /* Change this to whatever width you want. */\n",
       "    padding-top: 10px;\n",
       "    border-bottom:2px solid SlateGray; /* FireBrick; */\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.css()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba07330",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = lambda bb: bb.groupby('title').count().urn.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac40e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install distance\n",
    "\n",
    "import distance as dist\n",
    "\n",
    "def propose_corr(candidate_dict, cutoff = 3):\n",
    "    \"\"\" Try levenshtein for the candidate words\"\"\"\n",
    "    res = list()\n",
    "    for x in candidate_dict:\n",
    "        xl = list()\n",
    "        for y in candidate_dict[x]:\n",
    "            d = dist.levenshtein(x.lower(), y.lower())\n",
    "            if d <= cutoff:\n",
    "                xl.append((y, d))\n",
    "        xl.sort(key = lambda x:x[1])\n",
    "        if len(xl) > 0:\n",
    "            min_value = xl[0][1]\n",
    "            #print(min_value)\n",
    "            candidates = [(x,w[0],w[1]) for w in xl if w[1] == min_value] \n",
    "            the_candidate = candidates[0]\n",
    "            if len(candidates) > 1:\n",
    "                # heuristic so that if everything else is equal, choose the one with same first letter\n",
    "                # might create problems for aand ånd ...\n",
    "                smallset = [(x, w, s) for (x, w, s) in candidates if x.lower()[0] == w.lower()[0]]\n",
    "                if smallset != []:\n",
    "                    the_candidate = smallset[0]\n",
    "            res.append(the_candidate)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6bb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_candidates(lang_text = None, trans_text = None, diff_window = 0.05, cutoff_sim = 20):\n",
    "    \"\"\"Compute word equivalents between old_text and new_text. They are assumed to be two versions of the same text\"\"\"\n",
    "    \n",
    "    check = lambda w: combo[(combo['orig']/combo.loc[w]['trans']) < 1 + diff_window][1 - diff_window < (combo['orig']/combo.loc[w]['trans'])]\n",
    "    \n",
    "    # get frequencies and make dataframes\n",
    "    ag = dh.Counts(old_text).counts\n",
    "    an = dh.Counts(new_text).counts\n",
    "\n",
    "    combo = pd.concat([ag, an], axis = 1).fillna(0)\n",
    "\n",
    "    combo['sim'] = combo.ag/combo.an\n",
    "    \n",
    "    # candidate words are grabbed from words that have a similar frequency across two languages\n",
    "    subs = combo.loc[combo[combo['sim']] <= cutoff_diff]    \n",
    "    # search using function check() for words with similar frequency\n",
    "    candidate_dict = {x:check(x).index for x in subs.index}\n",
    "    \n",
    "    return candidate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a35aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_candidates_from_agg(orig_id = None, trans_id = None, diff_window = 0.05, cutoff = 10):\n",
    "    \"\"\"Compute word equivalents between text and its translation.\"\"\"\n",
    "    \n",
    "    check = lambda w: combo[(combo['orig']/combo.loc[w]['trans']) < 1 + diff_window][1 - diff_window < (combo['orig']/combo.loc[w]['trans'])]\n",
    "    \n",
    "    # get frequencies and make dataframes\n",
    "\n",
    "    orig_text = dh.Counts(orig_id).counts\n",
    "    trans_text = dh.Counts(trans_id).counts\n",
    "\n",
    "    combo = pd.concat([orig_text, trans_text], axis = 1).fillna(0)\n",
    "    combo.columns = [\"orig\", \"trans\"]\n",
    "    combo['sim'] = combo.orig/combo.combo.trans\n",
    "    \n",
    "    # candidate words are grabbed from words that have a sizable different frequency across the two versions\n",
    "    subs = combo.loc[combo[combo['orig'] <= cutoff][combo['trans'] >= cutoff].index]\n",
    "    \n",
    "    # search using function check() for words with similar frequency\n",
    "    candidate_dict = {x:check(x).index for x in subs.index}\n",
    "    \n",
    "    return candidate_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6493da7",
   "metadata": {},
   "source": [
    "## Bokpar\n",
    "\n",
    "Bokpar letes frem med metadata. Titler som har mer enn en oppføring, sjekkes for skrivemåter med bruk av konkordanser, for eksempel \"får\" vs \"faar\". Teksten som inneholder siste skrivemåte er den eldre. Konkordansene gir også et inntrykk av OCR-kvaliteten.\n",
    "\n",
    "### Forfatter\n",
    "\n",
    "Variabelen `forfatter` brukes til fil-lagring nedenfor. Her skal vi bruke korpus mot korpus. For Ibsen gjelder det samlede verker fra tidlig 1900-tall mot et moderne fra 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e0fd4",
   "metadata": {},
   "source": [
    "### Ordkoblinger\n",
    "\n",
    "Beregn kobling mellom ord, gammel til ny, og legg resultatet i en dataramme.\n",
    "\n",
    "Parametrene for make_candidates_from_agg er to aggregerte korpus. Deretter et krav om forskjell, og deretter en cutoff på frekvens. Lavfrekvente ord utgjør over halvparten av all tekst, og vil redusere presisjonen om alt tas med. En grense på 3 eller 4 virker ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fe4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
